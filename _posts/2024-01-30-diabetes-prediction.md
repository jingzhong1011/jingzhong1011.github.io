---
title: "以機器學習進行糖尿病預測之分析架構"
tags: 學習
modify_date: 2025-06-01
---

這項專案基於 Olisah 等人 (2022) 發表於《Computer Methods and Programs in Biomedicine》的論文。  
<!--more-->
該論文提出了一個用於糖尿病診斷與預測的資料處理與機器學習框架。我的目標是透過實際操作來驗證該論文提出的方法，並進一步探索如何利用新方法與集成學習來改進其機器學習模型，以期更精準地識別糖尿病發生風險。


---

### 背景
糖尿病是一種代謝疾病，其特徵為高血糖，通常源自人體對於胰島素的分泌及反應不足。糖尿病包括糖尿病前期(Prediabetes)、I 型與 II 型糖尿病、妊娠糖尿病 (Gestational diabetes) ，醫學上已經證明糖尿病與長期損害重要器官有關，包括眼睛、腎臟、神經、心臟和血管，因此糖尿病對於公共衛生及醫學上可說是急需關切之疾病。近年根據統計與機器學習的方法演進，在糖尿病研究領域有不少文獻使用機器學習方法協助臨床醫學上對於糖尿病之診斷做出快速之判斷。主要的方法如神經網路 (Neural Network, NN) 及基於其之方法。

### 資料
研究使用了兩個主要的資料集，它們也是 Olisah 等人論文中使用的資料：

1. PIMA 資料集： 該資料集由美國國家糖尿病、消化和腎臟疾病研究所 (NIDDK) 提供，包含了居住在亞利桑那州鳳凰城附近 PIMA 印第安社區的女性患者資料。所有患者均為至少 21 歲的 PIMA 印第安裔女性。資料變數包括：懷孕次數、血糖、血壓、皮褶厚度、胰島素、身體質量指數 (BMI)、糖尿病家族史功能 (DPF) 和年齡。

2. LMCH 資料集： 這是來自伊拉克國立醫學城醫院 (LMCH) 糖尿病資料庫，包含了 1000 名伊拉克患者的資料。資料變數包括：患者編號、血糖、年齡、性別、肌酐比 (Cr)、BMI、尿素、膽固醇 (Chol)、血脂、低密度脂蛋白 (LDL)、極低密度脂蛋白 (VLDL)、三酸甘油酯 (TG) 和糖化血色素 (HbA1c)。

### 資料預處理
資料處理框架使用了 Olisah 等人的資料處理方法，主要分為兩個階段：資料預處理和分類。該篇使用之資料預處理方法用於機器學習或是統計模型上已足夠良好，因此沿用其處理框架進行資料預處理。  

PIMA 資料集是預處理的重點，因為它存在大量缺失值，且部分變數的缺失百分比非常高。預處理流程包括：移除缺失值、選擇重要特徵值、以及填補缺失值，以確保機器學習模型的資料完整性。 LMCH 資料集因其完整性，僅需進行特徵選擇，無需處理缺失值。

- 缺失值移除： 根據美國糖尿病協會的規範，對血糖值進行重新標記（糖尿病：≥126 mg/dL；糖尿病前期：100−125 mg/dL；一般患者：0−99 mg/dL），並刪除所有含有缺失值的行。

- 特徵選擇： 採用 Spearman Correlation (SC) 進行特徵選擇。 SC 生成的 p 值衡量了每個預測變數與結果變數之間相關性的顯著機率， p 值越小，特徵的重要性越高。顯著性閾值設定為 0.01。為了解決特徵值之間競爭重要性的問題，我對 p 值進行了尺度縮放，以放大某些特徵相對於其他特徵的重要性。

- 缺失值填補： 缺失值填補採用多項式迴歸 (Polynomial Regression, PR)。在 PIMA 資料集中，僅使用前一步驟中選定的特徵進行缺失值插補。具體步驟如下：
  1. 首先檢查每個選定特徵的缺失值百分比，閾值設為 5%。
  2. 如果資料中某個變數的零值數量大於 5%（例如 PIMA 資料集中的胰島素），則進行下一步，否則刪除該行資料。
  3. 將與胰島素高度相關的特徵（例如血糖）添加為預測變數，用於預測胰島素。
  4. 將資料點分為非零資料集和零值資料集，其中非零之資料集用於訓練和測試，零值資料集則用於預測。最終將預測結果與非零資料集合併，形成完整的資料集。
  5. 在多項式迴歸中，考慮了 2 階、 7 階、 12 階和 17 階等多種迴歸模型，並評估了它們的性能。綜合比較不同迴歸模型的 均方根誤差 (RMSE) 和 決定係數 ($$R^2$$) 後，最終選擇了 7 階多項式迴歸來填補資料中的缺失值，因為它在此次評估中展現了足夠的模型擬合度。

### 機器學習預測方法
在我對糖尿病預測框架的實作與驗證中，我深入探討了多種機器學習模型。除了重現並分析原始論文中使用的 支持向量機 (SVM)、隨機森林 (Random Forest) 和 兩倍成長深度神經網路 (2GDNN)，我還引入了 K-最近鄰近法 (KNN) 和 XGBoost 這兩種方法，並結合了 集成學習 (Stacking) 來進一步提升預測性能。

#### 支持向量機 (SVM)
SVM 是一種強大的監督式學習模型，廣泛應用於分類與迴歸分析。其核心目標是在給定一組標記好的訓練實例（通常是二元分類），建立一個非機率性的線性分類器。SVM 透過將每個實例映射到多維空間中的點，並最大化不同類別之間的間隔來實現分類。對於非線性分類問題，SVM 能巧妙地運用核技巧 (Kernel Trick)，將輸入隱式映射到高維特徵空間中進行處理。

#### 隨機森林 (Random Forest)
隨機森林是一種基於決策樹的集成學習方法。它透過構建多個決策樹來進行分類，這些樹的建立過程涉及隨機採樣資料和隨機選擇特徵。每個決策樹獨立地對輸入樣本進行分類，最終結果則透過多數決 (Majority Voting) 的方式得出。這種將多個「弱分類器」組合為一個「強分類器」的策略，能顯著提升預測和分類的準確性。

#### 兩倍成長深度神經網路 (2GDNN)
2GDNN 是一種前饋式深度神經網路 (DNN)，它透過多個隱藏層和非線性激活函數來提取並轉換特徵。 DNN 的層次結構包括輸入層、隱藏層和輸出層，層間連接伴隨相關權重。神經元將資料傳遞至下一層的判斷，取決於其輸出是否高於激活函數所定義的閾值。訓練過程中，網路利用反向傳播 (Backpropagation) 演算法更新神經元權重，以最小化誤差並提升對未見樣本的泛化能力。原始論文特別設計了 2GDNN，其隱藏層的大小是輸入大小的兩倍，並且重複兩次，這種「兩倍成長」的結構由一個輸入層、四個隱藏層和一個輸出層組成。神經元的傳遞決策由函數決定，其中分別代表輸入、權重和偏差，而為激活函數。學習過程中，網路持續更新和以最小化目標輸出與網路預測輸出之間的差異。  
  
---
  
為了進一步探索和提升糖尿病預測模型的效能，引入了以下新的機器學習方法，並採用了集成學習策略：

#### K-最近鄰演算法 (KNN)
K-最近鄰演算法 (KNN) 是一種簡單直觀且用途廣泛的無母數監督式學習方法，可用於分類和迴歸問題。其核心原理是，對於給定的新輸入樣本，它會尋找訓練集中與之最接近的 K 個資料點，然後根據這些「鄰居」的類別進行投票來預測新樣本的類別，通常使用歐氏距離來衡量資料點之間的距離。KNN 的優點在於模型簡單易懂、適用於任何資料類型，對異常值不敏感，且在處理多類別分類問題時表現出色。

#### XGBoost
XGBoost 是一種基於 Boosting 框架的算法，可以視為由一系列基底模型 (Base Model) 疊加組成的加法模型。在每次迭代中，XGBoost 會優化前一步的子模型。XGBoost 透過貪婪演算法構建決策樹，不斷增加決策樹直到滿足停止條件，只有當增益大於閾值時才進行決策樹分裂。XGBoost 的優勢在於其多種防止過度擬合的機制，利用損失函數關於待求函數的二階導數進行優化，並提供交叉驗證和樣本權重控制，使其在機器學習領域中被廣泛應用。

#### 集成學習 (Stacking Method)
集成學習的核心思想是將多個分類器或模型組合起來，形成一個更強大的大模型。其原理是使用多個基底分類器 (Base Classifiers) 進行學習和擬合，然後將這些基底分類器的預測結果作為下一層（或稱為元分類器, Meta-Classifier）的輸入，最終由元分類器得出最終的預測結果。集成學習具備模型效果好、可解釋性強、適用於複雜資料等優點，因此在模型融合領域是一個熱門的研究方向。

在本次專案中，我使用的集成學習方法結合了兩種不同的基底分類器：基於距離演算法的 KNN 和迭代演算法的 XGBoost。這種組合旨在透過利用不同演算法的分類能力，更好地捕捉資料中的資訊，以實現模型融合的目的。隨後，使用邏輯斯迴歸 (Logistic Regression) 作為元分類器，來綜合各基底分類器的加權總和，以期獲得更高的預測性能。

### 結果及討論
#### 特徵值篩選的影響
我首先針對 PIMA 資料集，比較了有無進行特徵值篩選對 SVM、RF 和 2GDNN 方法的預測性能影響。結果顯示，在各模型中，經過特徵值篩選的預測準確率相較於未篩選的結果，提升了 0.7% 到 4% 不等。其中，SVM 和 2GDNN 的差異約為 0.7%，而 RF 方法在特徵值篩選與否的差異高達 4%，效果十分顯著。這項測試證明了特徵值篩選能夠有效幫助機器學習方法提升在分類預測上的表現。

| Model     | FS  | Precision(%) | F1-Score(%) | Train Acc.(%) | Test Acc.(%) |
| :-------- | :-- | :----------- | :---------- | :------------ | :----------- |
| SVM       | No  | 94.4       | 93.7      | 95.4        | 94         |
| SVM       | Yes | 94.1       | 94.3      | 95.3        | 94.7       |
| RF        | No  | 88.7       | 90.4      | 92          | 92.5       |
| RF        | Yes | 96.7       | 96        | 97.4        | 96.5       |
| 2GDNN     | No  | 96.1       | 96.1      | 100         | 96         |
| 2GDNN     | Yes | 97.3       | 97        | 98.7        | 96.7       |

#### 缺失值填補方法的比較
接著，我針對 LMCH 資料集，比較了不同缺失值填補方法對預測表現的影響，這些資料同樣經過了特徵值篩選。我比較了平均值 (Mean)、中位數 (Median)、鏈式方程式多重填補 (MICE) 和多項式迴歸 (PR) 這幾種填補方法。結果表明，使用多項式迴歸進行缺失值填補，其預測準確率相較於其他方法顯著更高。這說明在本次專案中，多項式迴歸填補缺失值確實能有效提升機器學習模型的預測能力。

| Preprocess   | Precision (%) | F1-Score (%) | Train Acc. (%) | Test Acc. (%) |
|--------------|---------------|--------------|----------------|---------------|
| FS+Mean      | 97            | 96.8         | 98.2           | 96.8          |
| FS+Median    | 97            | 96.8         | 98.2           | 96.8          |
| FS+Mice      | 96            | 95.6         | 98.2           | 95.5          |
| FS+PR        | 98.1          | 98           | 98.6           | 97.9          |


#### 模型效能比較
下表展示了本次專案中所有使用的機器學習模型效能。前三者 (SVM、Random Forest 和 2GDNN) 為原始論文中參考的方法，後兩者 (XGBoost、KNN) 則是我額外評估的新增方法。從 測試準確率 (Test Accuracy) 來看，2GDNN 的表現最高，其次是 Random Forest，接著依序是 XGBoost、KNN 和 SVM。

| Model   | Precision (%) | F1-Score (%) | Train Acc. (%) | Test Acc. (%) |
|---------|---------------|--------------|----------------|---------------|
| SVM     | 95.2          | 93.6         | 93.4           | 88.6          |
| RF      | 98.3          | 97.6         | 99.2           | 96.5          |
| 2GDNN   | 98            | 97.8         | 98             | 97.3          |
| XGBoost | 95.5          | 95.6         | 99.7           | 95.3          |
| KNN     | 90.5          | 90.7         | 92.4           | 91            |


為了進一步提升模型效能，我在 XGBoost 和 KNN 上應用了 Stacking 集成學習方法。如下表所示，無論是在 PIMA 資料集還是 LMCH 資料集上，模型的準確度都得到了顯著提高。這證明集成學習在本次糖尿病預測任務中具有顯著的優勢。

| Dataset | Precision (%) | F1-Score (%) | Test Acc. (%) |
|---------|---------------|--------------|----------------|
| PIMA    | 100           | 100          | 100            |
| LMCH    | 95.3          | 95.8         | 96.3           |


### 結論
本次專案的目標是透過資料前處理和機器學習方法，對糖尿病和糖尿病前期病情進行診斷及預測。利用 PIMA 印第安資料和 LMCH 伊拉克籍患者資料進行了處理和模型擬合。研究結果顯示，使用 Spearman Correlation 進行特徵值篩選以及多項式迴歸進行缺失值填補，能夠有效提高糖尿病診斷的準確率。

此外，針對多種機器學習方法進行了全面評估，包括原始論文中提及的 SVM、RF、2GDNN，以及我額外引入的 KNN、XGBoost 及其集成學習方法。結果表明，2GDNN 和 XGBoost 在糖尿病診斷分類評估上的表現令人滿意。更重要的是，透過應用 Stacking 集成學習方法，我成功地進一步提升了模型的預測性能。

透過這次實作與評估，我認為原始文章所提供的糖尿病預測方法及建立的框架是穩健且可信賴的。同時，我也證明了透過引入更先進的機器學習模型（如 XGBoost）和集成學習策略，可以進一步優化其性能，為糖尿病的精準診斷和預測提供更強大的工具。